{"cells":[{"cell_type":"markdown","metadata":{"id":"Ck00s7mTmnjA"},"source":["# Spaceship Titanic Dataset with XGBoost\n"]},{"cell_type":"markdown","metadata":{"id":"UPNzfVOEmnjH"},"source":["# Import the packages\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:33.954681Z","iopub.status.busy":"2023-07-14T18:17:33.953402Z","iopub.status.idle":"2023-07-14T18:17:33.967702Z","shell.execute_reply":"2023-07-14T18:17:33.965697Z","shell.execute_reply.started":"2023-07-14T18:17:33.954615Z"},"id":"mmwBzpblmnjH","trusted":true},"outputs":[],"source":["import os\n","import warnings\n","from pathlib import Path\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from IPython.display import display\n","from pandas.api.types import CategoricalDtype\n","\n","from category_encoders import MEstimateEncoder\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.feature_selection import mutual_info_regression\n","from sklearn.model_selection import cross_val_score\n","from sklearn.impute import KNNImputer\n","\n","\n","from xgboost import XGBClassifier\n","\n","# Set Matplotlib defaults\n","plt.style.use(\"seaborn-whitegrid\")\n","plt.rc(\"figure\", autolayout=True)\n","plt.rc(\n","    \"axes\",\n","    labelweight=\"bold\",\n","    labelsize=\"large\",\n","    titleweight=\"bold\",\n","    titlesize=14,\n","    titlepad=10,\n",")\n","\n","# Mute warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:33.971082Z","iopub.status.busy":"2023-07-14T18:17:33.970664Z","iopub.status.idle":"2023-07-14T18:17:33.984444Z","shell.execute_reply":"2023-07-14T18:17:33.983005Z","shell.execute_reply.started":"2023-07-14T18:17:33.971040Z"},"trusted":true},"outputs":[],"source":["# PATH = \"/kaggle/input/spaceship-titanic/\"\n","PATH = \"\""]},{"cell_type":"markdown","metadata":{},"source":["1. Sleep and spent\n","2. Deck and number of survivers\n"]},{"cell_type":"markdown","metadata":{"id":"6sHFpppPmnjJ"},"source":["# 1 - Date preprocessing\n"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:33.986908Z","iopub.status.busy":"2023-07-14T18:17:33.986402Z","iopub.status.idle":"2023-07-14T18:17:33.997987Z","shell.execute_reply":"2023-07-14T18:17:33.996383Z","shell.execute_reply.started":"2023-07-14T18:17:33.986852Z"},"trusted":true},"outputs":[],"source":["def load_data(PATH):\n","    # Read data\n","    data_dir = Path(PATH)\n","    df_train = pd.read_csv(data_dir / \"train.csv\")\n","    id_train = df_train.index\n","    df_test = pd.read_csv(data_dir / \"test.csv\")\n","    id_test = df_test.index + len(id_train)\n","    # Merge the splits so we can process them together\n","    df = pd.concat([df_train, df_test], ignore_index=True)\n","    # Cleaning\n","    df = clean(df)\n","    df = encode(df)\n","    # Reform splits\n","    df_train = df.loc[id_train, :]\n","    df_test = df.loc[id_test, :]\n","    return df_train, df_test"]},{"cell_type":"markdown","metadata":{},"source":["## Clean data\n"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:34.003414Z","iopub.status.busy":"2023-07-14T18:17:34.002920Z","iopub.status.idle":"2023-07-14T18:17:34.013587Z","shell.execute_reply":"2023-07-14T18:17:34.011996Z","shell.execute_reply.started":"2023-07-14T18:17:34.003368Z"},"trusted":true},"outputs":[],"source":["def bool_to_int(x):\n","    if str(x) == \"True\":\n","        return 1\n","    elif str(x) == \"False\":\n","        return 0\n","    else:\n","        return x\n","\n","\n","def clean(df):\n","    df[\"Transported\"] = df[\"Transported\"].astype(\"bool\")\n","\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["## Encode\n"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:34.018530Z","iopub.status.busy":"2023-07-14T18:17:34.017930Z","iopub.status.idle":"2023-07-14T18:17:34.031980Z","shell.execute_reply":"2023-07-14T18:17:34.030501Z","shell.execute_reply.started":"2023-07-14T18:17:34.018464Z"},"trusted":true},"outputs":[],"source":["def encode(df):\n","    features_nom = df.select_dtypes(exclude=[\"number\", \"bool\"])\n","\n","    for name in features_nom:\n","        df[name] = df[name].astype(\"category\")\n","\n","        if \"None\" not in df[name].cat.categories:\n","            df[name] = df[name].cat.add_categories(\"None\")\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["## Imput values\n"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:34.034380Z","iopub.status.busy":"2023-07-14T18:17:34.033865Z","iopub.status.idle":"2023-07-14T18:17:34.046563Z","shell.execute_reply":"2023-07-14T18:17:34.045217Z","shell.execute_reply.started":"2023-07-14T18:17:34.034330Z"},"trusted":true},"outputs":[],"source":["def label_encode_keeping_nulls(df):\n","    df_encoded = df.copy()\n","    for col in df.select_dtypes(\"category\").columns:\n","        indx = df.loc[~df[col].isna(), col].index\n","        categories = df[col].cat.categories\n","        df_encoded[col] = df[col].astype(\"object\")\n","        df_encoded.loc[indx, col] = df[col].cat.codes[indx]\n","    return df_encoded\n","\n","\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","def knn_impute(df, df_train=None):\n","    df_encoded = label_encode_keeping_nulls(df)\n","\n","    std_scaler = StandardScaler()\n","    df_scaled = df_encoded.copy()\n","    df_scaled[df_scaled.columns] = std_scaler.fit_transform(df_encoded)\n","\n","    knn_imputer = KNNImputer()\n","    knn_cat_features = [\"VIP\", \"CryoSleep\"]\n","    if df_train is not None:\n","        knn_imputer.fit(df_scaled.loc[df_train.index])\n","    else:\n","        knn_imputer.fit(df_scaled)\n","    df_scaled[df_scaled.columns] = knn_imputer.transform(df_scaled)\n","\n","    df_encoded[df_encoded.columns] = std_scaler.inverse_transform(df_scaled)\n","\n","    df_encoded = df_encoded.round(0)\n","    for name in knn_cat_features:\n","        df_encoded[name] = (\n","            df_encoded[name].astype(\"category\").cat.add_categories(\"None\")\n","        )\n","        new_categories = df[name].astype(\"category\").cat.categories\n","        df[name] = (\n","            df_encoded[name].astype(\"category\").cat.rename_categories(new_categories)\n","        )\n","\n","    num_features = df.select_dtypes(\"number\").columns\n","    df[num_features] = df_encoded[num_features]\n","\n","    return df\n","\n","\n","def impute(df_train, df_test=None):\n","    df = df_train.copy()\n","    if df_test is not None:\n","        df = pd.concat([df, df_test])\n","    y = df.pop(target)\n","\n","    feature_bfills = [\"Cabin\", \"HomePlanet\", \"Destination\"]\n","    df[feature_bfills] = df[feature_bfills].fillna(method=\"bfill\")\n","\n","    if df_test is not None:\n","        df = knn_impute(df, df_train)\n","    else:\n","        df = knn_impute(df)\n","\n","    for name in df.select_dtypes(\"number\"):\n","        df[name] = df[name].fillna(0).astype(\"int\")\n","\n","    for name in df.select_dtypes(exclude=[\"number\"]):\n","        if df[name].isna().sum() != 0:\n","            df[name] = df[name].fillna(\"None\")\n","        else:\n","            df[name] = df[name].cat.remove_categories(\"None\")\n","\n","    df = pd.concat([df, y], axis=1)\n","    if df_test is not None:\n","        return df.loc[df_train.index, :], df.loc[df_test.index, :]\n","\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["# 2 - Features engineering\n"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:34.049584Z","iopub.status.busy":"2023-07-14T18:17:34.048713Z","iopub.status.idle":"2023-07-14T18:17:34.067350Z","shell.execute_reply":"2023-07-14T18:17:34.065963Z","shell.execute_reply.started":"2023-07-14T18:17:34.049528Z"},"trusted":true},"outputs":[],"source":["def mathematical_transforms(df):\n","    X = pd.DataFrame()\n","    X[\"RS_FC_SM\"] = df[[\"RoomService\", \"FoodCourt\", \"ShoppingMall\"]].sum(axis=1)\n","    df[\"VR_SPA\"] = df[[\"Spa\", \"VRDeck\"]].sum(axis=1)\n","\n","    return X\n","\n","\n","def interactions(df):\n","    X = pd.DataFrame()\n","\n","    dummies_sleep = pd.get_dummies(df.CryoSleep, prefix=\"CryoSleep_VR_SPA\")\n","    sleep_VR_SPA = dummies_sleep.mul(df.VR_SPA, axis=0)\n","\n","    dummies_sleep = pd.get_dummies(df.CryoSleep, prefix=\"CryoSleep_RFM\")\n","    sleep_RFS = dummies_sleep.mul(df.RS_FC_SM, axis=0)\n","\n","    X = pd.concat([sleep_VR_SPA, sleep_RFS], axis=1)\n","\n","    return X\n","\n","\n","def counts(df):\n","    X = pd.DataFrame()\n","    return X\n","\n","\n","def break_down(df):\n","    X = pd.DataFrame()\n","\n","    X[[\"Group\", \"Id\"]] = df.PassengerId.str.split(\"_\", expand=True)\n","    X[\"Group\"] = X.Group.astype(\"int\")\n","    X.pop(\"Id\")\n","\n","    X[[\"Deck\", \"Cabin_num\", \"Side\"]] = df.Cabin.str.split(\"/\", expand=True)\n","    X[[\"Deck\", \"Side\"]] = X[[\"Deck\", \"Side\"]].fillna(\"None\")\n","    X[\"Cabin_num\"] = X.Cabin_num.fillna(0).astype(\"int\")\n","\n","    X[[\"First Name\", \"Surname\"]] = df.Name.str.split(\" \", expand=True).fillna(\"None\")\n","    X.pop(\"First Name\")\n","    for name in [\"Deck\", \"Side\", \"Surname\"]:\n","        X[name] = X[name].astype(\"category\")\n","\n","        if \"None\" not in X[name].cat.categories:\n","            X[name] = X[name].cat.add_categories(\"None\")\n","\n","    return X\n","\n","\n","def group_transform(df):\n","    X = pd.DataFrame()\n","\n","    X[\"Diff_VR_SPA\"] = df[\"VR_SPA\"] - df.groupby(by=[\"CryoSleep\"])[\"VR_SPA\"].transform(\n","        \"median\"\n","    )\n","    X[\"Diff_RS_FC_SM\"] = df[\"RS_FC_SM\"] - df.groupby(by=[\"CryoSleep\"])[\n","        \"RS_FC_SM\"\n","    ].transform(\"median\")\n","\n","    return X"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:34.070569Z","iopub.status.busy":"2023-07-14T18:17:34.069629Z","iopub.status.idle":"2023-07-14T18:17:34.088059Z","shell.execute_reply":"2023-07-14T18:17:34.086970Z","shell.execute_reply.started":"2023-07-14T18:17:34.070513Z"},"trusted":true},"outputs":[],"source":["def label_encode(df):\n","    X = df.copy()\n","    for colname in X.select_dtypes([\"category\"]):\n","        X[colname] = X[colname].cat.codes\n","    return X"]},{"cell_type":"markdown","metadata":{},"source":["# k-Means Clustering\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["def cluster_labels(df, features, n_clusters=20):\n","    X = df.copy()\n","    X_scaled = X.loc[:, features]\n","    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n","    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0)\n","    X_new = pd.DataFrame()\n","    X_new[\"Clusters\"] = kmeans.fit_predict(X_scaled)\n","    return X_new\n","\n","\n","def cluster_distance(df, features, n_clusters=20):\n","    X = df.copy()\n","    X_scaled = X.loc[:, features]\n","    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n","    kmeans = KMeans(n_clusters=20, n_init=50, random_state=0)\n","    X_cd = kmeans.fit_transform(X_scaled)\n","    # Label features and join to dataset\n","    X_cd = pd.DataFrame(X_cd, columns=[f\"Centroid_{i}\" for i in range(X_cd.shape[1])])\n","    return X_cd"]},{"cell_type":"markdown","metadata":{},"source":["# Create final feature set\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:34.107791Z","iopub.status.busy":"2023-07-14T18:17:34.106978Z","iopub.status.idle":"2023-07-14T18:17:34.120882Z","shell.execute_reply":"2023-07-14T18:17:34.119799Z","shell.execute_reply.started":"2023-07-14T18:17:34.107740Z"},"trusted":true},"outputs":[],"source":["def create_features(df, df_test=None):\n","    X = df.copy()\n","    y = X.pop(target)\n","    #     y = df.loc[:, target]\n","\n","    # Combine splits if test data is given\n","    #\n","    # If we're creating features for test set predictions, we should\n","    # use all the data we have available. After creating our features,\n","    # we'll recreate the splits.\n","    if df_test is not None:\n","        X_test = df_test.copy()\n","        if target in X_test.columns:\n","            X_test.pop(target)\n","        X = pd.concat([X, X_test])\n","\n","    # Transformations\n","    X = X.join(break_down(X))\n","    X = X.join(mathematical_transforms(X))\n","    X = X.join(interactions(X))\n","    #     X = X.join(counts(X))\n","    X = X.join(group_transform(X))\n","\n","    X.drop([\"PassengerId\", \"Name\", \"Cabin\", \"Surname\", \"Group\"], axis=1, inplace=True)\n","\n","    # Clustering\n","    # cluster_features_1 = [\"Spa\", \"VRDeck\"]\n","    # X = X.join(cluster_labels(X, cluster_features_1, n_clusters=5))\n","    # X = X.join(cluster_distance(X, cluster_features, n_clusters=20))\n","\n","    # PCA\n","    # pca_features = X.select_dtypes(exclude=\"category\").columns\n","    # X = X.join(pca_inspired(X))\n","    # X = X.join(pca_components(X, pca_features))\n","    # X = X.join(indicate_outliers(X))\n","\n","    X = label_encode(X)\n","\n","    cluster_features = [\n","        \"CryoSleep\",\n","        \"Side\",\n","        \"Deck\",\n","        \"FoodCourt\",\n","        \"ShoppingMall\",\n","        \"Spa\",\n","        \"VRDeck\",\n","        \"Deck\",\n","    ]\n","    X = X.join(cluster_labels(X, cluster_features, n_clusters=10))\n","\n","    # Reform splits\n","    if df_test is not None:\n","        X_test = X.loc[df_test.index, :]\n","        X.drop(df_test.index, inplace=True)\n","\n","    # Target Encoder\n","    #     encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n","    #     X = X.join(encoder.fit_transform(X, y, cols=[\"MSSubClass\"]))\n","    #     if df_test is not None:\n","    #         X_test = X_test.join(encoder.transform(X_test))\n","\n","    if df_test is not None:\n","        return X, X_test\n","    else:\n","        return X"]},{"cell_type":"markdown","metadata":{},"source":["# Cross validation\n"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:17:34.123389Z","iopub.status.busy":"2023-07-14T18:17:34.122550Z","iopub.status.idle":"2023-07-14T18:17:34.140098Z","shell.execute_reply":"2023-07-14T18:17:34.138781Z","shell.execute_reply.started":"2023-07-14T18:17:34.123336Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import StratifiedKFold\n","from sklearn.base import clone\n","from pprint import pprint\n","\n","\n","def score_dataset(X, y, model=XGBClassifier()):\n","    score = []\n","    skf = StratifiedKFold(random_state=0, shuffle=True)\n","    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n","        X_train, X_test = X.loc[train_index], X.loc[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        X_train, X_test = impute(X_train, X_test)\n","        X_train, X_test = create_features(X_train, X_test)\n","\n","        model_local = clone(model)\n","        model_local.fit(X_train, y_train)\n","        score.append(model_local.score(X_test, y_test))\n","\n","    return score"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:26:48.621805Z","iopub.status.busy":"2023-07-14T18:26:48.620642Z","iopub.status.idle":"2023-07-14T18:31:27.333754Z","shell.execute_reply":"2023-07-14T18:31:27.332676Z","shell.execute_reply.started":"2023-07-14T18:26:48.621754Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8096161901440653\n"]}],"source":["df_train, _ = load_data(PATH)\n","target = \"Transported\"\n","y_train = df_train.loc[:, target].astype(\"bool\")\n","\n","\n","xgb_params = dict(\n","    max_depth=8,\n","    learning_rate=0.1,\n","    n_estimators=400,\n","    min_child_weight=2,\n","    colsample_bytree=0.4,\n","    subsample=0.6,\n","    reg_alpha=7,\n","    reg_lambda=5,\n",")\n","xgb = XGBClassifier(**xgb_params)\n","\n","print(np.mean(score_dataset(df_train, y_train, xgb)))"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# df_train, _ = load_data(PATH)\n","# target = \"Transported\"\n","# y_train = df_train.loc[:, target].astype(\"bool\")\n","\n","\n","# for p in np.arange(0, 10, 1):\n","# xgb_params = dict(\n","#     max_depth=8,\n","#     learning_rate=0.1,\n","#     n_estimators=400,\n","#     min_child_weight=2,\n","#     colsample_bytree=0.4,\n","#     subsample=0.6,\n","#     reg_alpha=7,\n","#     reg_lambda=5,\n","# )\n","#     xgb = XGBClassifier(**xgb_params)\n","\n","#     print(p)\n","#     print(np.mean(score_dataset(df_train, y_train, xgb)))\n","#     print('--------------------------------')"]},{"cell_type":"markdown","metadata":{},"source":["# 3- Train model and create submission\n"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-07-14T18:23:11.140671Z","iopub.status.busy":"2023-07-14T18:23:11.140265Z","iopub.status.idle":"2023-07-14T18:24:27.499615Z","shell.execute_reply":"2023-07-14T18:24:27.498498Z","shell.execute_reply.started":"2023-07-14T18:23:11.140633Z"},"trusted":true},"outputs":[],"source":["df_train, df_test = load_data(PATH)\n","target = \"Transported\"\n","X_train, X_test = impute(df_train, df_test)\n","X_train, X_test = create_features(X_train, X_test)\n","y_train = df_train.loc[:, target].to_numpy()\n","\n","xgb = XGBClassifier(**xgb_params)\n","xgb.fit(X_train, y_train)\n","predictions = xgb.predict(X_test).astype(\"bool\")\n","\n","output = pd.DataFrame(\n","    {\"PassengerId\": df_test.PassengerId, \"Transported\": predictions.squeeze()}\n",")\n","\n","output.to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
